{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alan/.local/conda/lib/python3.7/site-packages/pandas_datareader/compat/__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    }
   ],
   "source": [
    "# Importing modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "import requests_cache\n",
    "\n",
    "# module for keras\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.models\n",
    "import tensorflow.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2468 entries, 2010-01-04 to 2020-01-10\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   High       2468 non-null   float64\n",
      " 1   Low        2468 non-null   float64\n",
      " 2   Open       2468 non-null   float64\n",
      " 3   Close      2468 non-null   float64\n",
      " 4   Volume     2468 non-null   float64\n",
      " 5   Adj Close  2468 non-null   float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 135.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Define the cache to store the data\n",
    "\n",
    "expire_after = datetime.timedelta(days=300)\n",
    "\n",
    "local_cache = requests_cache.CachedSession(cache_name='cache', backend='sqlite', expire_after=expire_after)\n",
    "\n",
    "# Downloading the data of 0005.hk from yahoo finance\n",
    "\n",
    "start = datetime.datetime(2010, 1, 1)\n",
    "end = datetime.datetime(2020, 1, 11)\n",
    "\n",
    "df = web.DataReader(\"0005.HK\", 'yahoo', start, end, session=local_cache)\n",
    "\n",
    "# Show the labels\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ndarray from the dataframe\n",
    "\n",
    "adj_close = df[\"Adj Close\"].values\n",
    "volume    = df[\"Volume\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rate of changes of adj_close\n",
    "\n",
    "adj_close_chg = (adj_close[1:-1] - adj_close[0:-2]) / adj_close[0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rate of changes of volume\n",
    "\n",
    "volume_chg = (volume[1:-1] - volume[0:-2]) / (volume[1:-1] + volume[0:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the array adj_close_chg\n",
    "\n",
    "tmp = np.sqrt(np.mean(np.square(adj_close_chg)))\n",
    "adj_close_chg /= tmp\n",
    "\n",
    "# Normalize the array volume\n",
    "\n",
    "tmp = np.sqrt(np.mean(np.square(volume_chg)))\n",
    "volume_chg /= tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1972,) (1972,)\n",
      "(494,) (494,)\n"
     ]
    }
   ],
   "source": [
    "# Split the 80% dataset to training set\n",
    "\n",
    "adj_close_chg_training = adj_close_chg[:int(len(adj_close_chg)*0.8)]\n",
    "volume_chg_training = volume_chg[:int(len(volume_chg)*0.8)]\n",
    "\n",
    "# Split the 20% dataset to testing set\n",
    "\n",
    "adj_close_chg_testing  = adj_close_chg[int(len(adj_close_chg)*0.8):]\n",
    "volume_chg_testing  = volume_chg[int(len(volume_chg)*0.8):]\n",
    "\n",
    "# Print the size of the above data sets for checking\n",
    "\n",
    "print((adj_close_chg_training.shape), (volume_chg_training.shape))\n",
    "print((adj_close_chg_testing.shape), (volume_chg_testing.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of steps to look advance\n",
    "\n",
    "N_step = int(10)\n",
    "\n",
    "# Generating training patterns\n",
    "\n",
    "target_training = [adj_close_chg_training[i] for i in range(N_step,len(adj_close_chg_training))]\n",
    "pattern_training = [np.concatenate((adj_close_chg_training[i-N_step:i],volume_chg_training[i-N_step:i]))\n",
    "                    for i in range(N_step,len(adj_close_chg_training))]\n",
    "\n",
    "target_training = np.array(target_training)\n",
    "pattern_training = np.array(pattern_training)\n",
    "\n",
    "# Generating testing patterns\n",
    "\n",
    "target_testing = [adj_close_chg_testing[i] for i in range(N_step,len(adj_close_chg_testing))]\n",
    "pattern_testing = [np.concatenate((adj_close_chg_testing[i-N_step:i],volume_chg_testing[i-N_step:i]))\n",
    "                    for i in range(N_step,len(adj_close_chg_testing))]\n",
    "\n",
    "target_testing = np.array(target_testing)\n",
    "pattern_testing = np.array(pattern_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making targets binary\n",
    "\n",
    "tmp = np.heaviside(target_training, 0)\n",
    "tmp = np.array([tmp, 1-tmp]).transpose()\n",
    "target_training = tmp\n",
    "\n",
    "tmp = np.heaviside(target_testing, 0)\n",
    "tmp = np.array([tmp, 1-tmp]).transpose()\n",
    "target_testing = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tensorflow model\n",
    "\n",
    "model = tensorflow.keras.models.Sequential()\n",
    "\n",
    "model.add(tensorflow.keras.layers.Dense(100, activation='tanh', input_shape=pattern_training[0].shape))\n",
    "model.add(tensorflow.keras.layers.Dropout(0.1))\n",
    "model.add(tensorflow.keras.layers.Dense(10, activation='sigmoid'))\n",
    "model.add(tensorflow.keras.layers.Dense(target_training.shape[1], activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.7346 - accuracy: 0.4959\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.7045 - accuracy: 0.4873\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.5046\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.5087\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.5010\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6957 - accuracy: 0.5025\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.4944\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5102\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5102\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.4995\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5250\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.5097\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.5061\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.4918\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5092\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5046\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5153\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5056\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.5168\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1423ec7fd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(pattern_training, target_training, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
